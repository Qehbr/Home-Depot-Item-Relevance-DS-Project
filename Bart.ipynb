{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T15:11:13.245679Z",
     "start_time": "2024-03-11T15:11:13.167326Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from math import sqrt\n",
    "from transformers import BartTokenizer, BartModel\n",
    "\n",
    "from bart_utils.BartDataset import BartDataset\n",
    "from bart_utils.BartSiamese import BartSiamese\n",
    "from bart_utils.bart_utils import *\n",
    "from utils.ClassicalML import *\n",
    "from utils.GLOBALS import *\n",
    "from utils.new_preproc import *"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define bart\n",
    "bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "bart_model = BartModel.from_pretrained('facebook/bart-base').to(device)\n",
    "bart_model.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa09d8f9768e1cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read and preprocess descriptions\n",
    "descriptions = pd.read_csv('product_descriptions.csv')\n",
    "descriptions['product_description'] = descriptions['product_description'].apply(\n",
    "    lambda x: get_bart_embeddings(x, bart_tokenizer, bart_model))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T13:42:44.407828Z",
     "start_time": "2024-03-11T13:27:06.644366Z"
    }
   },
   "id": "11de4a8445437983",
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read and preprocess train\n",
    "train = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
    "train = pd.merge(train, descriptions, on='product_uid')\n",
    "train = train[['search_term', 'product_description', 'relevance']]\n",
    "train['search_term'] = train['search_term'].apply(get_bart_embeddings)\n",
    "train['relevance'] = train['relevance'].apply(min_max_scaling)\n",
    "\n",
    "# read and preprocess test\n",
    "test = pd.read_csv('test.csv', encoding='ISO-8859-1')\n",
    "test = pd.merge(test, descriptions, on='product_uid')\n",
    "test_sol = pd.read_csv('solution.csv')\n",
    "test = pd.merge(test, test_sol, on='id')\n",
    "test['search_term'] = test['search_term'].apply(get_bart_embeddings)\n",
    "test = test[['search_term', 'product_description', 'relevance']]\n",
    "test = test[test['relevance'] != -1].reset_index()\n",
    "test['relevance'] = test['relevance'].apply(min_max_scaling)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:08:37.453283Z",
     "start_time": "2024-03-11T13:42:44.413762Z"
    }
   },
   "id": "e4142917b4654c53",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = BartDataset(train['search_term'], train['product_description'], train['relevance'])\n",
    "test_dataset = BartDataset(test['search_term'], test['product_description'], test['relevance'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T14:08:37.482802Z",
     "start_time": "2024-03-11T14:08:37.457072Z"
    }
   },
   "id": "31c9ee7850f0b03a",
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n",
      "Epoch 1 (3.6s), Train RMSE: 0.6505565709724405, Val RMSE: 0.6126509045425054, Train MAE: 0.5399867419123966, Val MAE: 0.5165034627341477\n",
      "New best model saved at epoch 1 with Val RMSE: 0.6127\n",
      "Epoch 2 (3.5s), Train RMSE: 0.5999916382645302, Val RMSE: 0.5791824644408086, Train MAE: 0.4984012950577861, Val MAE: 0.48679927613903545\n",
      "New best model saved at epoch 2 with Val RMSE: 0.5792\n",
      "Epoch 3 (3.1s), Train RMSE: 0.5627257009835366, Val RMSE: 0.5602225671193396, Train MAE: 0.46446619923783966, Val MAE: 0.46717770219219346\n",
      "New best model saved at epoch 3 with Val RMSE: 0.5602\n",
      "Epoch 4 (2.9s), Train RMSE: 0.5297977963637842, Val RMSE: 0.5488809092297694, Train MAE: 0.4353335676792895, Val MAE: 0.4572575960192134\n",
      "New best model saved at epoch 4 with Val RMSE: 0.5489\n",
      "Epoch 5 (3.5s), Train RMSE: 0.49768739760645797, Val RMSE: 0.5544900725447603, Train MAE: 0.4091832199561502, Val MAE: 0.4601547104298095\n",
      "Epoch 6 (3.3s), Train RMSE: 0.467045226715859, Val RMSE: 0.5024685629907921, Train MAE: 0.3850449543616871, Val MAE: 0.41052147689756635\n",
      "New best model saved at epoch 6 with Val RMSE: 0.5025\n",
      "Epoch 7 (3.1s), Train RMSE: 0.4434787516958955, Val RMSE: 0.5106241528776163, Train MAE: 0.36568288749444033, Val MAE: 0.42087471747070054\n",
      "Epoch 8 (2.8s), Train RMSE: 0.42673141614511023, Val RMSE: 0.4863575787956432, Train MAE: 0.35125436058342674, Val MAE: 0.39549303622530335\n",
      "New best model saved at epoch 8 with Val RMSE: 0.4864\n",
      "Epoch 9 (3.3s), Train RMSE: 0.41346272358432395, Val RMSE: 0.49397813279156644, Train MAE: 0.3400336229925713, Val MAE: 0.4023142673152652\n",
      "Epoch 10 (3.4s), Train RMSE: 0.4027724623032263, Val RMSE: 0.47947899538458544, Train MAE: 0.32990591597714397, Val MAE: 0.38799903363661353\n",
      "New best model saved at epoch 10 with Val RMSE: 0.4795\n",
      "Epoch 11 (3.4s), Train RMSE: 0.39318398674914656, Val RMSE: 0.48699691520788385, Train MAE: 0.32095565491180716, Val MAE: 0.39254134973888055\n",
      "Epoch 12 (3.4s), Train RMSE: 0.38470521064444907, Val RMSE: 0.48747781673531243, Train MAE: 0.31303997147671353, Val MAE: 0.3932854536816677\n",
      "Epoch 13 (3.3s), Train RMSE: 0.3772639043681089, Val RMSE: 0.48400819938599693, Train MAE: 0.305744425476049, Val MAE: 0.38931007476668616\n",
      "Epoch 14 (3.2s), Train RMSE: 0.37069996809860817, Val RMSE: 0.4895141361840936, Train MAE: 0.29964417718256453, Val MAE: 0.3931438671893978\n",
      "Epoch 15 (3.3s), Train RMSE: 0.3628965609971344, Val RMSE: 0.4909413677768243, Train MAE: 0.29264418783494556, Val MAE: 0.3924714048148264\n",
      "Epoch 16 (3.1s), Train RMSE: 0.35650257648370115, Val RMSE: 0.4929371933484977, Train MAE: 0.2874330433207122, Val MAE: 0.39293864057568445\n",
      "Epoch 17 (3.3s), Train RMSE: 0.3492709284276252, Val RMSE: 0.4978466943701111, Train MAE: 0.28114479305898965, Val MAE: 0.39427650555821425\n",
      "Epoch 18 (3.2s), Train RMSE: 0.3440346205224152, Val RMSE: 0.5039336923302784, Train MAE: 0.2760741960791003, Val MAE: 0.39956559696885696\n",
      "Epoch 19 (3.2s), Train RMSE: 0.33807259643838317, Val RMSE: 0.4972439019540378, Train MAE: 0.2711820869462459, Val MAE: 0.3912103759408786\n",
      "Epoch 20 (3.3s), Train RMSE: 0.33326853683386193, Val RMSE: 0.49856463009951585, Train MAE: 0.2665535792907823, Val MAE: 0.3957490075716078\n",
      "Epoch 21 (3.2s), Train RMSE: 0.3284561318266873, Val RMSE: 0.5039158866333019, Train MAE: 0.2623552841754764, Val MAE: 0.39724986180934696\n",
      "Epoch 22 (3.3s), Train RMSE: 0.32318354486356915, Val RMSE: 0.4998006982335756, Train MAE: 0.2583769039460066, Val MAE: 0.39369138369148876\n",
      "Epoch 23 (3.3s), Train RMSE: 0.31741259187663906, Val RMSE: 0.5060912346931751, Train MAE: 0.2526363625815916, Val MAE: 0.39947159133878685\n",
      "Epoch 24 (3.2s), Train RMSE: 0.3140842215007752, Val RMSE: 0.50472417267769, Train MAE: 0.249525280859799, Val MAE: 0.3969003672507734\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[164], line 47\u001B[0m\n\u001B[0;32m     44\u001B[0m total_train_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m search_term, product_description, relevance \u001B[38;5;129;01min\u001B[39;00m train_data_loader:\n\u001B[1;32m---> 47\u001B[0m     search_term, product_description, relevance \u001B[38;5;241m=\u001B[39m search_term\u001B[38;5;241m.\u001B[39mto(device), product_description\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m     48\u001B[0m         device), relevance\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     49\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     50\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(search_term, product_description)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# train parameters\n",
    "embedding_dim = 768\n",
    "hidden_dim1 = 512\n",
    "hidden_dim2 = 256\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "# stratify validation set\n",
    "binned_labels = pd.qcut(train['relevance'], q=3, labels=False, duplicates='drop')\n",
    "train_indices, val_indices = train_test_split(range(len(train_dataset)), test_size=0.2, stratify=binned_labels,\n",
    "                                              random_state=42)\n",
    "\n",
    "# split train to train-val\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(train_dataset, val_indices)\n",
    "train_data_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_data_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# model, metrics, optimizer\n",
    "model = BartSiamese(embedding_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "mse_loss = MSELoss()\n",
    "mae_loss = L1Loss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# used for saving best model\n",
    "best_val_rmse = float('inf')\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_mse_train_loss = 0\n",
    "    total_mae_train_loss = 0\n",
    "    total_train_samples = 0\n",
    "    # train loop\n",
    "    for search_term, product_description, relevance in train_data_loader:\n",
    "        search_term, product_description, relevance = search_term.to(device), product_description.to(\n",
    "            device), relevance.to(device)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(search_term, product_description).squeeze(1)\n",
    "        loss_mse = mse_loss(outputs, relevance)\n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # inverse labels for correct calculation of metrics\n",
    "        loss_mse = mse_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "        loss_mae = mae_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "\n",
    "        total_mse_train_loss += loss_mse.item() * len(relevance)\n",
    "        total_mae_train_loss += loss_mae.item() * len(relevance)\n",
    "        total_train_samples += len(relevance)\n",
    "\n",
    "    train_rmse = sqrt(total_mse_train_loss / total_train_samples)\n",
    "    train_mae = total_mae_train_loss / total_train_samples\n",
    "\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    total_mse_val_loss = 0\n",
    "    total_mae_val_loss = 0\n",
    "    total_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for search_term, product_description, relevance in val_data_loader:\n",
    "            search_term, product_description, relevance = search_term.to(device), product_description.to(\n",
    "                device), relevance.to(device)\n",
    "            outputs = model(search_term, product_description).squeeze(1)\n",
    "\n",
    "            val_loss_mse = mse_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "            val_loss_mae = mae_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "\n",
    "            total_mse_val_loss += val_loss_mse.item() * len(relevance)\n",
    "            total_mae_val_loss += val_loss_mae.item() * len(relevance)\n",
    "            total_val_samples += len(relevance)\n",
    "\n",
    "    val_rmse = sqrt(total_mse_val_loss / total_val_samples)\n",
    "    val_mae = total_mae_val_loss / total_val_samples\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} ({epoch_time:.1f}s), Train RMSE: {train_rmse}, Val RMSE: {val_rmse}, Train MAE: {train_mae}, Val MAE: {val_mae}\")\n",
    "\n",
    "    # save best model\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), 'best_model_character.pth')\n",
    "        print(f\"New best model saved at epoch {epoch + 1} with Val RMSE: {best_val_rmse:.4f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training time: {training_time:.4f}s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:12:07.193499Z",
     "start_time": "2024-03-11T17:10:46.597013Z"
    }
   },
   "id": "e675a9505c41efd1",
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model\n",
    "model = BartSiamese(embedding_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "model.load_state_dict(torch.load('best_model_character.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:12:09.003092Z",
     "start_time": "2024-03-11T17:12:08.990719Z"
    }
   },
   "id": "4618a7ef080bb061",
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time: 3.2s, Test RMSE: 0.5198253001883457, Test MAE: 0.4223737092737296\n"
     ]
    }
   ],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "model.eval()\n",
    "total_mse_test_loss = 0\n",
    "total_mae_test_loss = 0\n",
    "total_test_samples = 0\n",
    "test_start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    # testing loop\n",
    "    for search_term, product_description, relevance in test_data_loader:\n",
    "        search_term, product_description, relevance = search_term.to(device), product_description.to(\n",
    "            device), relevance.to(device)\n",
    "        outputs = model(search_term, product_description).squeeze(1)\n",
    "\n",
    "        test_loss_mse = mse_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "        test_loss_mae = mae_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "\n",
    "        total_mse_test_loss += test_loss_mse.item() * len(relevance)\n",
    "        total_mae_test_loss += test_loss_mae.item() * len(relevance)\n",
    "        total_test_samples += len(relevance)\n",
    "\n",
    "test_time = time.time() - test_start_time\n",
    "test_rmse = sqrt(total_mse_test_loss / total_test_samples)\n",
    "test_mae = total_mae_test_loss / total_test_samples\n",
    "print(f'Test time: {test_time:.1f}s, Test RMSE: {test_rmse}, Test MAE: {test_mae}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:16:03.414005Z",
     "start_time": "2024-03-11T17:16:00.254361Z"
    }
   },
   "id": "3b4abf16dc7a1dbe",
   "execution_count": 167
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get train/test data for classical ML algorithms\n",
    "all_train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "X_train, y_train, X_test, y_test = get_classical_ml_train_test_data(model, all_train_data_loader, test_data_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e0132494448c635"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.15100494442402046\n",
      "Root Mean Squared Error (RMSE): 0.20607646491599785\n",
      "Mean Absolute Error (MAE): 0.43745403175373826\n",
      "Root Mean Squared Error (RMSE): 0.540144015528063\n"
     ]
    }
   ],
   "source": [
    "train_rf(X_train, y_train, X_test, y_test, n_estimators=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:19:59.312748Z",
     "start_time": "2024-03-11T17:16:33.489355Z"
    }
   },
   "id": "c39b62ff37d2a6c8",
   "execution_count": 169
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Absolute Error (MAE): 0.4202823489661842\n",
      "Train Root Mean Squared Error (RMSE): 0.5111906005392803\n",
      "Test Mean Absolute Error (MAE): 0.4343958323631227\n",
      "Test Root Mean Squared Error (RMSE): 0.529577572795704\n"
     ]
    }
   ],
   "source": [
    "train_gbr(X_train, y_train, X_test, y_test, n_estimators=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:20:43.605631Z",
     "start_time": "2024-03-11T17:19:59.313751Z"
    }
   },
   "id": "c7dbb2750aca3e44",
   "execution_count": 170
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Absolute Error (MAE): 0.38856953382492065\n",
      "Train Root Mean Squared Error (RMSE): 0.4797027111053467\n",
      "Test Mean Absolute Error (MAE): 0.4337574243545532\n",
      "Test Root Mean Squared Error (RMSE): 0.5349620580673218\n"
     ]
    }
   ],
   "source": [
    "train_linear_regression(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:20:43.889059Z",
     "start_time": "2024-03-11T17:20:43.606644Z"
    }
   },
   "id": "c992bd19a7649bc2",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Absolute Error (MAE): 0.34970012307167053\n",
      "Train Root Mean Squared Error (RMSE): 0.42272648215293884\n",
      "Test Mean Absolute Error (MAE): 0.4265356957912445\n",
      "Test Root Mean Squared Error (RMSE): 0.5222816467285156\n"
     ]
    }
   ],
   "source": [
    "train_xgboost(X_train, y_train, X_test, y_test, n_estimators=10, learning_rate=0.09, max_depth=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T17:35:20.116208Z",
     "start_time": "2024-03-11T17:35:19.070328Z"
    }
   },
   "id": "6a387b60f0ab4337",
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea93c85c66442a52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
