{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-10T12:36:26.215190Z",
     "start_time": "2024-03-10T12:36:26.211755Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import MSELoss, L1Loss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from math import sqrt\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from utils.ClassicalML import *\n",
    "from utils.new_preproc import *\n",
    "from word_utils.WordDataset import WordDataset\n",
    "from word_utils.WordSiameseLSTM import WordSiameseLSTM\n",
    "from word_utils.word_utils import *\n",
    "from utils.GLOBALS import *\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read and preprocess descriptions\n",
    "descriptions = pd.read_csv('csv/product_descriptions.csv')\n",
    "descriptions['product_description'] = descriptions['product_description'].apply(\n",
    "    lambda x: preprocess_text(x, drop_stopwords=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T13:17:32.842418Z",
     "start_time": "2024-03-10T12:38:16.484591Z"
    }
   },
   "id": "11de4a8445437983",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read and preprocess train\n",
    "train = pd.read_csv('csv/train.csv', encoding='ISO-8859-1')\n",
    "train = pd.merge(train, descriptions, on='product_uid')\n",
    "train = train[['search_term', 'product_description', 'relevance']]\n",
    "train['search_term'] = train['search_term'].apply(lambda x: preprocess_text(x, drop_stopwords=False))\n",
    "train['relevance'] = train['relevance'].apply(min_max_scaling)\n",
    "\n",
    "# read and preprocess test\n",
    "test = pd.read_csv('csv/test.csv', encoding='ISO-8859-1')\n",
    "test = pd.merge(test, descriptions, on='product_uid')\n",
    "test_sol = pd.read_csv('csv/solution.csv')\n",
    "test = pd.merge(test, test_sol, on='id')\n",
    "test['search_term'] = test['search_term'].apply(lambda x: preprocess_text(x, drop_stopwords=False))\n",
    "test = test[['search_term', 'product_description', 'relevance']]\n",
    "test = test[test['relevance'] != -1].reset_index()\n",
    "test['relevance'] = test['relevance'].apply(min_max_scaling)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T21:09:33.604263Z",
     "start_time": "2024-03-10T21:07:24.924525Z"
    }
   },
   "id": "e4142917b4654c53",
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get all tokens and train word2vec model\n",
    "all_tokens = list(train['search_term']) + list(train['product_description']) + list(test['search_term']) + list(\n",
    "    test['product_description'])\n",
    "word2vec_model = Word2Vec(sentences=all_tokens, vector_size=64, window=7, min_count=1, workers=4)\n",
    "word2vec_model.save(\"word2vec.model\")\n",
    "\n",
    "# we tried normalizing word2vec model inputs but it did not perform well\n",
    "# word2vec_model.wv.fill_norms()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T21:31:45.557490Z",
     "start_time": "2024-03-10T21:31:18.218005Z"
    }
   },
   "id": "c74b9c69c1712bd7",
   "execution_count": 246
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get train and test datasets\n",
    "train_dataset = WordDataset(train['search_term'], train['product_description'], train['relevance'], word2vec_model)\n",
    "test_dataset = WordDataset(test['search_term'], test['product_description'], test['relevance'], word2vec_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T21:31:45.563215Z",
     "start_time": "2024-03-10T21:31:45.558492Z"
    }
   },
   "id": "31c9ee7850f0b03a",
   "execution_count": 247
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n",
      "Epoch 1 (23.8s), Train RMSE: 0.6134094162715071, Val RMSE: 0.5464724379159154, Train MAE: 0.5039927574018285, Val MAE: 0.4448336077851774\n",
      "New best model saved at epoch 1 with Val RMSE: 0.5465\n",
      "Epoch 2 (22.4s), Train RMSE: 0.5283244204494473, Val RMSE: 0.5322457182070796, Train MAE: 0.43524895884076376, Val MAE: 0.4338613074527862\n",
      "New best model saved at epoch 2 with Val RMSE: 0.5322\n",
      "Epoch 3 (22.8s), Train RMSE: 0.5221979014541914, Val RMSE: 0.5248814521025891, Train MAE: 0.43005353640130267, Val MAE: 0.4271986302623579\n",
      "New best model saved at epoch 3 with Val RMSE: 0.5249\n",
      "Epoch 4 (23.0s), Train RMSE: 0.5171902524754555, Val RMSE: 0.5199784545359663, Train MAE: 0.4260117705713543, Val MAE: 0.4245337900586564\n",
      "New best model saved at epoch 4 with Val RMSE: 0.5200\n",
      "Epoch 5 (22.8s), Train RMSE: 0.5136077832143948, Val RMSE: 0.5116403284183498, Train MAE: 0.4231072901686586, Val MAE: 0.41883682798273864\n",
      "New best model saved at epoch 5 with Val RMSE: 0.5116\n",
      "Epoch 6 (22.9s), Train RMSE: 0.5102515307480217, Val RMSE: 0.5074693697640161, Train MAE: 0.42026865173709577, Val MAE: 0.41659541975893405\n",
      "New best model saved at epoch 6 with Val RMSE: 0.5075\n",
      "Epoch 7 (22.7s), Train RMSE: 0.507594942116986, Val RMSE: 0.5077697844370698, Train MAE: 0.4179185485147962, Val MAE: 0.4142257279554359\n",
      "Epoch 8 (23.9s), Train RMSE: 0.5057521963520341, Val RMSE: 0.5063074911587707, Train MAE: 0.41600171536342495, Val MAE: 0.4141022691411883\n",
      "New best model saved at epoch 8 with Val RMSE: 0.5063\n",
      "Epoch 9 (23.1s), Train RMSE: 0.5039848225995649, Val RMSE: 0.5040229821857329, Train MAE: 0.41448675304489807, Val MAE: 0.4104831410400681\n",
      "New best model saved at epoch 9 with Val RMSE: 0.5040\n",
      "Epoch 10 (23.0s), Train RMSE: 0.5023881576743293, Val RMSE: 0.5038486484731901, Train MAE: 0.41309920760005236, Val MAE: 0.4102538391350251\n",
      "New best model saved at epoch 10 with Val RMSE: 0.5038\n",
      "Epoch 11 (22.8s), Train RMSE: 0.500472770147656, Val RMSE: 0.5008399243094441, Train MAE: 0.41093277081047724, Val MAE: 0.4076343417304464\n",
      "New best model saved at epoch 11 with Val RMSE: 0.5008\n",
      "Epoch 12 (22.9s), Train RMSE: 0.49942074574937917, Val RMSE: 0.49797237668142985, Train MAE: 0.41008636541799776, Val MAE: 0.4063551758961815\n",
      "New best model saved at epoch 12 with Val RMSE: 0.4980\n",
      "Epoch 13 (22.9s), Train RMSE: 0.49798049231464553, Val RMSE: 0.5011346248289119, Train MAE: 0.4089006746812963, Val MAE: 0.4050798519099951\n",
      "Epoch 14 (23.0s), Train RMSE: 0.4976680777380968, Val RMSE: 0.496981833992697, Train MAE: 0.4085436013139914, Val MAE: 0.4056537347121874\n",
      "New best model saved at epoch 14 with Val RMSE: 0.4970\n",
      "Epoch 15 (23.1s), Train RMSE: 0.4955400388564092, Val RMSE: 0.4972303515719359, Train MAE: 0.406948325747794, Val MAE: 0.40305673480194815\n",
      "Epoch 16 (23.0s), Train RMSE: 0.49387700289839614, Val RMSE: 0.49701470949519744, Train MAE: 0.40480677103049895, Val MAE: 0.40129799368540187\n",
      "Epoch 17 (22.8s), Train RMSE: 0.49261052866701277, Val RMSE: 0.49814150821669145, Train MAE: 0.40381675337971756, Val MAE: 0.4016607896597968\n",
      "Epoch 18 (22.8s), Train RMSE: 0.4925214607883275, Val RMSE: 0.493777392326374, Train MAE: 0.4035871062639194, Val MAE: 0.40025205837178685\n",
      "New best model saved at epoch 18 with Val RMSE: 0.4938\n",
      "Epoch 19 (23.1s), Train RMSE: 0.49111443356832013, Val RMSE: 0.49308017904223506, Train MAE: 0.4014068860227125, Val MAE: 0.40304706238116655\n",
      "New best model saved at epoch 19 with Val RMSE: 0.4931\n",
      "Epoch 20 (23.0s), Train RMSE: 0.4914146989420378, Val RMSE: 0.49504897953761257, Train MAE: 0.4026667481499592, Val MAE: 0.4003660805604872\n",
      "Epoch 21 (22.8s), Train RMSE: 0.49146216027236417, Val RMSE: 0.4929357157209503, Train MAE: 0.402399972326381, Val MAE: 0.39968727929994163\n",
      "New best model saved at epoch 21 with Val RMSE: 0.4929\n",
      "Epoch 22 (22.8s), Train RMSE: 0.4902331781054195, Val RMSE: 0.49366060884930396, Train MAE: 0.4014899517700863, Val MAE: 0.3986820257738468\n",
      "Epoch 23 (23.0s), Train RMSE: 0.48855594350349923, Val RMSE: 0.4924108335596065, Train MAE: 0.39980573382411505, Val MAE: 0.3979271266710522\n",
      "New best model saved at epoch 23 with Val RMSE: 0.4924\n",
      "Epoch 24 (23.0s), Train RMSE: 0.48766984071686836, Val RMSE: 0.49420255880478364, Train MAE: 0.39912496588422186, Val MAE: 0.39938879128939325\n",
      "Epoch 25 (23.1s), Train RMSE: 0.48876833198722447, Val RMSE: 0.4927874013542255, Train MAE: 0.39975561474608223, Val MAE: 0.399694599634693\n",
      "Epoch 26 (22.9s), Train RMSE: 0.4879305334699285, Val RMSE: 0.4924333605766953, Train MAE: 0.39913719259165387, Val MAE: 0.3998530979088577\n",
      "Epoch 27 (23.0s), Train RMSE: 0.4860009650196231, Val RMSE: 0.49242669575339304, Train MAE: 0.39747975082296305, Val MAE: 0.4006631023667836\n",
      "Epoch 28 (22.9s), Train RMSE: 0.485807063361769, Val RMSE: 0.49289477908781953, Train MAE: 0.3976124292452836, Val MAE: 0.39862732012068774\n",
      "Epoch 29 (22.9s), Train RMSE: 0.4864590884743019, Val RMSE: 0.4933969382036096, Train MAE: 0.39773837110946875, Val MAE: 0.3997956183664194\n",
      "Epoch 30 (23.1s), Train RMSE: 0.4852856001244044, Val RMSE: 0.4925356053879002, Train MAE: 0.39674841213686635, Val MAE: 0.40100708749108555\n",
      "Epoch 31 (23.0s), Train RMSE: 0.4853020864196443, Val RMSE: 0.4913040866726341, Train MAE: 0.39662595092269487, Val MAE: 0.3980986213931932\n",
      "New best model saved at epoch 31 with Val RMSE: 0.4913\n",
      "Epoch 32 (22.9s), Train RMSE: 0.4858122077138581, Val RMSE: 0.49028051293029024, Train MAE: 0.39726449900344785, Val MAE: 0.39893413336392564\n",
      "New best model saved at epoch 32 with Val RMSE: 0.4903\n",
      "Epoch 33 (22.8s), Train RMSE: 0.48388286611859493, Val RMSE: 0.49044564359731785, Train MAE: 0.3955309912573687, Val MAE: 0.39671449574668416\n",
      "Epoch 34 (22.9s), Train RMSE: 0.48395468101586464, Val RMSE: 0.4901379104759241, Train MAE: 0.395085620550281, Val MAE: 0.39864151128490427\n",
      "New best model saved at epoch 34 with Val RMSE: 0.4901\n",
      "Epoch 35 (23.1s), Train RMSE: 0.48287609569132134, Val RMSE: 0.4910439138473609, Train MAE: 0.39425045507906975, Val MAE: 0.39687665385628285\n",
      "Epoch 36 (22.8s), Train RMSE: 0.48260758329978515, Val RMSE: 0.4904527863039229, Train MAE: 0.39402482082412715, Val MAE: 0.39650340309280835\n",
      "Epoch 37 (23.0s), Train RMSE: 0.4828668413296924, Val RMSE: 0.4893014557600248, Train MAE: 0.3941978760980432, Val MAE: 0.39847152627752075\n",
      "New best model saved at epoch 37 with Val RMSE: 0.4893\n",
      "Epoch 38 (22.9s), Train RMSE: 0.48223094130489325, Val RMSE: 0.4907317118052155, Train MAE: 0.39396485041246604, Val MAE: 0.39640836090762815\n",
      "Epoch 39 (23.0s), Train RMSE: 0.4817066644461694, Val RMSE: 0.4898071228608701, Train MAE: 0.3934172109359649, Val MAE: 0.39539101519081876\n",
      "Epoch 40 (23.0s), Train RMSE: 0.4803432760280554, Val RMSE: 0.4924956497688571, Train MAE: 0.39211744367860046, Val MAE: 0.39535350105178907\n",
      "Epoch 41 (23.1s), Train RMSE: 0.48084038470904295, Val RMSE: 0.48970236680699053, Train MAE: 0.39223686690781406, Val MAE: 0.3952888129202319\n",
      "Epoch 42 (22.9s), Train RMSE: 0.48236575614536276, Val RMSE: 0.48905470502542, Train MAE: 0.39348074851153886, Val MAE: 0.3956777980948196\n",
      "New best model saved at epoch 42 with Val RMSE: 0.4891\n",
      "Epoch 43 (22.9s), Train RMSE: 0.4809771127682254, Val RMSE: 0.492041769985598, Train MAE: 0.39253693846508037, Val MAE: 0.3959027674615955\n",
      "Epoch 44 (22.9s), Train RMSE: 0.4804893045052786, Val RMSE: 0.49104179703821366, Train MAE: 0.39211510559378776, Val MAE: 0.39613308588856866\n",
      "Epoch 45 (23.3s), Train RMSE: 0.48118531189650554, Val RMSE: 0.48738083438455637, Train MAE: 0.3928282400427968, Val MAE: 0.39381890991720025\n",
      "New best model saved at epoch 45 with Val RMSE: 0.4874\n",
      "Epoch 46 (23.2s), Train RMSE: 0.4797705876082058, Val RMSE: 0.48817568208806356, Train MAE: 0.391216944643667, Val MAE: 0.39554918479449486\n",
      "Epoch 47 (22.9s), Train RMSE: 0.48041317343955514, Val RMSE: 0.4892637218179806, Train MAE: 0.39197016163344944, Val MAE: 0.39438893048003953\n",
      "Epoch 48 (23.0s), Train RMSE: 0.4792123996744828, Val RMSE: 0.4898819141379496, Train MAE: 0.3908875053192238, Val MAE: 0.39515459717760465\n",
      "Epoch 49 (22.5s), Train RMSE: 0.4802451600784449, Val RMSE: 0.49063063756524355, Train MAE: 0.39170936032574666, Val MAE: 0.3954903247772609\n",
      "Epoch 50 (23.2s), Train RMSE: 0.4798779089590219, Val RMSE: 0.48874563877615496, Train MAE: 0.3915327366787844, Val MAE: 0.39479201426949595\n",
      "Epoch 51 (22.6s), Train RMSE: 0.4791625411055932, Val RMSE: 0.49058682860782676, Train MAE: 0.39075940171609963, Val MAE: 0.3962379292556917\n",
      "Epoch 52 (23.0s), Train RMSE: 0.4790525090357253, Val RMSE: 0.48834845303418584, Train MAE: 0.3907077150353057, Val MAE: 0.39355746699406324\n",
      "Epoch 53 (23.0s), Train RMSE: 0.47806137728317144, Val RMSE: 0.4880512564956645, Train MAE: 0.3898910761257748, Val MAE: 0.3936522093816407\n",
      "Epoch 54 (22.9s), Train RMSE: 0.47849785641728276, Val RMSE: 0.48769265561572916, Train MAE: 0.39030264996970077, Val MAE: 0.39426010855138743\n",
      "Epoch 55 (23.1s), Train RMSE: 0.4782292001217716, Val RMSE: 0.48831607277167577, Train MAE: 0.38985647234912985, Val MAE: 0.3943517879265208\n",
      "Epoch 56 (23.2s), Train RMSE: 0.4781430327792914, Val RMSE: 0.4877046159714912, Train MAE: 0.38956705054234825, Val MAE: 0.39373002485078534\n",
      "Epoch 57 (23.2s), Train RMSE: 0.4783254580196443, Val RMSE: 0.48870323547414024, Train MAE: 0.39001588198345283, Val MAE: 0.3918805744132324\n",
      "Epoch 58 (23.0s), Train RMSE: 0.47673643124400333, Val RMSE: 0.4882097372282815, Train MAE: 0.38867377567727435, Val MAE: 0.3930141994855625\n",
      "Epoch 59 (22.9s), Train RMSE: 0.4776814918254638, Val RMSE: 0.48844657610073466, Train MAE: 0.3889122058226123, Val MAE: 0.39289712482205574\n",
      "Epoch 60 (23.1s), Train RMSE: 0.4780887034199321, Val RMSE: 0.4881017590199309, Train MAE: 0.38971336296459225, Val MAE: 0.39404210085342234\n",
      "Epoch 61 (22.8s), Train RMSE: 0.4776791977963283, Val RMSE: 0.48916362410707775, Train MAE: 0.38949544147956405, Val MAE: 0.39615479834700656\n",
      "Epoch 62 (23.1s), Train RMSE: 0.4770208186588824, Val RMSE: 0.49022006339514906, Train MAE: 0.38873528892810083, Val MAE: 0.3932332619048974\n",
      "Epoch 63 (22.8s), Train RMSE: 0.4751846973601571, Val RMSE: 0.488708866681831, Train MAE: 0.3865869086993796, Val MAE: 0.39468298981397987\n",
      "Epoch 64 (22.9s), Train RMSE: 0.4767414925295448, Val RMSE: 0.4874103827095475, Train MAE: 0.38865838126106317, Val MAE: 0.3916702203878076\n",
      "Epoch 65 (22.9s), Train RMSE: 0.47610847609565204, Val RMSE: 0.4876163026708404, Train MAE: 0.3881198039177072, Val MAE: 0.39419959578675684\n",
      "Epoch 66 (22.9s), Train RMSE: 0.4768218808534037, Val RMSE: 0.4868386858588423, Train MAE: 0.38799225015292044, Val MAE: 0.391573555708189\n",
      "New best model saved at epoch 66 with Val RMSE: 0.4868\n",
      "Epoch 67 (23.1s), Train RMSE: 0.47623402739565196, Val RMSE: 0.4883703258910417, Train MAE: 0.3876241430376917, Val MAE: 0.39374717474144705\n",
      "Epoch 68 (22.9s), Train RMSE: 0.47682719033061177, Val RMSE: 0.4857175334734764, Train MAE: 0.3883238679993161, Val MAE: 0.39154292232870846\n",
      "New best model saved at epoch 68 with Val RMSE: 0.4857\n",
      "Epoch 69 (23.0s), Train RMSE: 0.4755853053413388, Val RMSE: 0.4877026333867639, Train MAE: 0.3870327253216979, Val MAE: 0.3931656538056059\n",
      "Epoch 70 (22.9s), Train RMSE: 0.4753800249399564, Val RMSE: 0.4877391203191527, Train MAE: 0.38685091530612986, Val MAE: 0.3936647989617293\n",
      "Epoch 71 (23.0s), Train RMSE: 0.47524839660493784, Val RMSE: 0.48794157100565977, Train MAE: 0.38692470680143737, Val MAE: 0.39145269379194764\n",
      "Epoch 72 (23.1s), Train RMSE: 0.4764522204080497, Val RMSE: 0.4864908625734773, Train MAE: 0.388414572561296, Val MAE: 0.3920641274318306\n",
      "Epoch 73 (23.0s), Train RMSE: 0.4755595560814468, Val RMSE: 0.4876378818939242, Train MAE: 0.3872438662832116, Val MAE: 0.39267809987390057\n",
      "Epoch 74 (23.1s), Train RMSE: 0.4757051887620876, Val RMSE: 0.4873922835555164, Train MAE: 0.3874072521915416, Val MAE: 0.39227887773233755\n",
      "Epoch 75 (23.0s), Train RMSE: 0.4753844025489534, Val RMSE: 0.4894397271208054, Train MAE: 0.38699272926866946, Val MAE: 0.39440847800314566\n",
      "Epoch 76 (23.0s), Train RMSE: 0.4749102030889013, Val RMSE: 0.4881115931183818, Train MAE: 0.3869161775365125, Val MAE: 0.3920467967878908\n",
      "Epoch 77 (23.1s), Train RMSE: 0.4750696245478111, Val RMSE: 0.49045180442902014, Train MAE: 0.3867853753950365, Val MAE: 0.39392907858152404\n",
      "Epoch 78 (22.9s), Train RMSE: 0.4742609978668619, Val RMSE: 0.48686262917269935, Train MAE: 0.3862317659997812, Val MAE: 0.39204129116793013\n",
      "Epoch 79 (22.9s), Train RMSE: 0.4744206520910672, Val RMSE: 0.4889056227138066, Train MAE: 0.3855735427847054, Val MAE: 0.3958153018660756\n",
      "Epoch 80 (22.9s), Train RMSE: 0.4748421693351701, Val RMSE: 0.48695728227802454, Train MAE: 0.38633260756120935, Val MAE: 0.3945604499710609\n",
      "Epoch 81 (22.9s), Train RMSE: 0.4741183657527835, Val RMSE: 0.48784298445543306, Train MAE: 0.38554299205147785, Val MAE: 0.39273216413537454\n",
      "Epoch 82 (23.0s), Train RMSE: 0.474108346575212, Val RMSE: 0.48693745492751284, Train MAE: 0.38580228433149016, Val MAE: 0.39128190087486703\n",
      "Epoch 83 (22.7s), Train RMSE: 0.4744925757496505, Val RMSE: 0.488094535535757, Train MAE: 0.3859614284755212, Val MAE: 0.3934285166140621\n",
      "Epoch 84 (22.9s), Train RMSE: 0.4732205144355905, Val RMSE: 0.48621605189118894, Train MAE: 0.3853054182210729, Val MAE: 0.39067257547468665\n",
      "Epoch 85 (22.4s), Train RMSE: 0.4747320325765786, Val RMSE: 0.48750765743492364, Train MAE: 0.38632263128194916, Val MAE: 0.3928652540768659\n",
      "Epoch 86 (22.4s), Train RMSE: 0.47366977990005565, Val RMSE: 0.4863785065843158, Train MAE: 0.38573579158553284, Val MAE: 0.3910498437135345\n",
      "Epoch 87 (22.8s), Train RMSE: 0.4745358524100717, Val RMSE: 0.48828785428143473, Train MAE: 0.3864321756174403, Val MAE: 0.3930468520236849\n",
      "Epoch 88 (23.2s), Train RMSE: 0.4741817509222444, Val RMSE: 0.4872137122069913, Train MAE: 0.3856378601859548, Val MAE: 0.392023459461129\n",
      "Epoch 89 (23.1s), Train RMSE: 0.4732189328287405, Val RMSE: 0.4870591816228223, Train MAE: 0.3855703361703984, Val MAE: 0.3910500344210378\n",
      "Epoch 90 (22.9s), Train RMSE: 0.47394288160033354, Val RMSE: 0.4874638608002669, Train MAE: 0.38541028228825785, Val MAE: 0.3916729956732534\n",
      "Epoch 91 (23.0s), Train RMSE: 0.4742339473166514, Val RMSE: 0.48883997814854707, Train MAE: 0.3860232614531142, Val MAE: 0.3955846096647885\n",
      "Epoch 92 (23.1s), Train RMSE: 0.47456044653672896, Val RMSE: 0.48732204775495647, Train MAE: 0.3857036331444393, Val MAE: 0.39247480080696484\n",
      "Epoch 93 (23.1s), Train RMSE: 0.4735412100705114, Val RMSE: 0.48771168178116975, Train MAE: 0.38529808471819005, Val MAE: 0.39290346102835566\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[257], line 45\u001B[0m\n\u001B[0;32m     42\u001B[0m total_mae_train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     43\u001B[0m total_train_samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m search_term, product_description, relevance \u001B[38;5;129;01min\u001B[39;00m train_data_loader:\n\u001B[0;32m     46\u001B[0m     search_term, product_description, relevance \u001B[38;5;241m=\u001B[39m search_term\u001B[38;5;241m.\u001B[39mto(device), product_description\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m     47\u001B[0m         device), relevance\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     48\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlworkshop\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[1;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "Cell \u001B[1;32mIn[255], line 18\u001B[0m, in \u001B[0;36mcustom_collate_fn\u001B[1;34m(batch)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Stack padded sequences and relevances\u001B[39;00m\n\u001B[0;32m     17\u001B[0m search_terms_padded \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(search_terms_padded)\n\u001B[1;32m---> 18\u001B[0m product_descriptions_padded \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(product_descriptions_padded)\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m search_terms_padded, product_descriptions_padded, relevances\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# train parameters\n",
    "embedding_dim = word2vec_model.vector_size\n",
    "hidden_dim = 64\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "\n",
    "# stratify validation set\n",
    "binned_labels = pd.qcut(train['relevance'], q=3, labels=False, duplicates='drop')\n",
    "train_indices, val_indices = train_test_split(range(len(train_dataset)), test_size=0.2, stratify=binned_labels,\n",
    "                                              random_state=42)\n",
    "\n",
    "# split train to train-val\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(train_dataset, val_indices)\n",
    "train_data_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
    "val_data_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "\n",
    "# model, metrics, optimizer\n",
    "model = WordSiameseLSTM(embedding_dim, hidden_dim).to(device)\n",
    "mse_loss = MSELoss()\n",
    "mae_loss = L1Loss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# used for saving best model\n",
    "best_val_rmse = float('inf')\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    total_mse_train_loss = 0\n",
    "    total_mae_train_loss = 0\n",
    "    total_train_samples = 0\n",
    "    # train loop\n",
    "    for search_term, product_description, relevance in train_data_loader:\n",
    "        search_term, product_description, relevance = search_term.to(device), product_description.to(\n",
    "            device), relevance.to(device)\n",
    "\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(search_term, product_description).squeeze(1)\n",
    "        loss_mse = mse_loss(outputs, relevance)\n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # inverse labels for correct calculation of metrics\n",
    "        loss_mse = mse_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "        loss_mae = mae_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "\n",
    "        total_mse_train_loss += loss_mse.item() * len(relevance)\n",
    "        total_mae_train_loss += loss_mae.item() * len(relevance)\n",
    "        total_train_samples += len(relevance)\n",
    "\n",
    "    train_rmse = sqrt(total_mse_train_loss / total_train_samples)\n",
    "    train_mae = total_mae_train_loss / total_train_samples\n",
    "\n",
    "    # validation loop\n",
    "    model.eval()\n",
    "    total_mse_val_loss = 0\n",
    "    total_mae_val_loss = 0\n",
    "    total_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for search_term, product_description, relevance in val_data_loader:\n",
    "            search_term, product_description, relevance = search_term.to(device), product_description.to(\n",
    "                device), relevance.to(device)\n",
    "            outputs = model(search_term, product_description).squeeze(1)\n",
    "\n",
    "            val_loss_mse = mse_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "            val_loss_mae = mae_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "\n",
    "            total_mse_val_loss += val_loss_mse.item() * len(relevance)\n",
    "            total_mae_val_loss += val_loss_mae.item() * len(relevance)\n",
    "            total_val_samples += len(relevance)\n",
    "\n",
    "    val_rmse = sqrt(total_mse_val_loss / total_val_samples)\n",
    "    val_mae = total_mae_val_loss / total_val_samples\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1} ({epoch_time:.1f}s), Train RMSE: {train_rmse}, Val RMSE: {val_rmse}, Train MAE: {train_mae}, Val MAE: {val_mae}\")\n",
    "\n",
    "    # save best model\n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), 'best_model_character.pth')\n",
    "        print(f\"New best model saved at epoch {epoch + 1} with Val RMSE: {best_val_rmse:.4f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training time: {training_time:.4f}s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T22:20:19.372963Z",
     "start_time": "2024-03-10T21:44:41.366987Z"
    }
   },
   "id": "e675a9505c41efd1",
   "execution_count": 257
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model\n",
    "model = WordSiameseLSTM(embedding_dim, hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load('best_model_character.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T22:28:48.954714Z",
     "start_time": "2024-03-10T22:28:48.946864Z"
    }
   },
   "id": "4618a7ef080bb061",
   "execution_count": 262
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time: 29.5s, Test RMSE: 0.5213677305455144, Test MAE: 0.4189072535836368\n"
     ]
    }
   ],
   "source": [
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=pad_collate_fn)\n",
    "model.eval()\n",
    "total_mse_test_loss = 0\n",
    "total_mae_test_loss = 0\n",
    "total_test_samples = 0\n",
    "test_start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    # testing loop\n",
    "    for search_term, product_description, relevance in test_data_loader:\n",
    "        search_term, product_description, relevance = search_term.to(device), product_description.to(\n",
    "            device), relevance.to(device)\n",
    "        outputs = model(search_term, product_description).squeeze(1)\n",
    "\n",
    "        test_loss_mse = mse_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "        test_loss_mae = mae_loss(inverse_min_max_scaling(outputs), inverse_min_max_scaling(relevance))\n",
    "\n",
    "        total_mse_test_loss += test_loss_mse.item() * len(relevance)\n",
    "        total_mae_test_loss += test_loss_mae.item() * len(relevance)\n",
    "        total_test_samples += len(relevance)\n",
    "\n",
    "test_time = time.time() - test_start_time\n",
    "test_rmse = sqrt(total_mse_test_loss / total_test_samples)\n",
    "test_mae = total_mae_test_loss / total_test_samples\n",
    "print(f'Test time: {test_time:.1f}s, Test RMSE: {test_rmse}, Test MAE: {test_mae}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T22:21:41.810248Z",
     "start_time": "2024-03-10T22:21:12.264492Z"
    }
   },
   "id": "3b4abf16dc7a1dbe",
   "execution_count": 260
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get train/test data for classical ML algorithms\n",
    "all_train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)\n",
    "X_train, y_train, X_test, y_test = get_classical_ml_train_test_data(model, all_train_data_loader, test_data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T23:38:50.066887Z",
     "start_time": "2024-03-10T23:38:28.483706Z"
    }
   },
   "id": "e371c959ecf06634",
   "execution_count": 288
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.1471460350646687\n",
      "Root Mean Squared Error (RMSE): 0.19857533087745619\n",
      "Mean Absolute Error (MAE): 0.4354615000130297\n",
      "Root Mean Squared Error (RMSE): 0.5408949218885898\n"
     ]
    }
   ],
   "source": [
    "train_rf(X_train, y_train, X_test, y_test, n_estimators=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T23:50:09.458400Z",
     "start_time": "2024-03-10T23:48:25.042343Z"
    }
   },
   "id": "c39b62ff37d2a6c8",
   "execution_count": 328
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Absolute Error (MAE): 0.3906506054622651\n",
      "Train Root Mean Squared Error (RMSE): 0.47260190316357914\n",
      "Test Mean Absolute Error (MAE): 0.4250206947224775\n",
      "Test Root Mean Squared Error (RMSE): 0.5169295549319173\n"
     ]
    }
   ],
   "source": [
    "train_gbr(X_train, y_train, X_test, y_test, n_estimators=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T23:48:25.041340Z",
     "start_time": "2024-03-10T23:47:56.590731Z"
    }
   },
   "id": "c7dbb2750aca3e44",
   "execution_count": 327
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Absolute Error (MAE): 0.3706657588481903\n",
      "Train Root Mean Squared Error (RMSE): 0.45788851380348206\n",
      "Test Mean Absolute Error (MAE): 0.425370991230011\n",
      "Test Root Mean Squared Error (RMSE): 0.5269988775253296\n"
     ]
    }
   ],
   "source": [
    "train_linear_regression(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T23:39:21.006176Z",
     "start_time": "2024-03-10T23:39:20.879438Z"
    }
   },
   "id": "c992bd19a7649bc2",
   "execution_count": 290
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Absolute Error (MAE): 0.35695117712020874\n",
      "Train Root Mean Squared Error (RMSE): 0.4309508800506592\n",
      "Test Mean Absolute Error (MAE): 0.4214370846748352\n",
      "Test Root Mean Squared Error (RMSE): 0.5144940614700317\n"
     ]
    }
   ],
   "source": [
    "train_xgboost(X_train, y_train, X_test, y_test, n_estimators=10, learning_rate=0.09, max_depth=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-10T23:45:40.914372Z",
     "start_time": "2024-03-10T23:45:39.525765Z"
    }
   },
   "id": "6a387b60f0ab4337",
   "execution_count": 325
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
